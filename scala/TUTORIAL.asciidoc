== Scala: An Opinionated Guide

This Guide is split up into two parts:

* Important Bits
* Parts To Avoid (And Their Alternatives)

I do not cover all features of Scala. I think it would be unnecessary to
do so with the aim of teaching you enough Scala to make you dangerous.

The intended audience is one of the following:

* An operations engineer who has written a fair bit of Ruby, Python, or Perl (gah)
* Someone that has done some OO development before
* A software engineer new to Scala and wants to know only the 'good parts' to
  get started quickly and make up their own mind later what works for them.
* Someone who is somewhat familiar with Scala on a basic level but is just
  used to writing Scala as if it is a less verbose Java. This audience should
  be prepared to unlearn a few things about Scala. Good luck. :)

I do have strong opinions on Scala style and form. This will become obvious to
you, especially in the second part of this which will be more design based and
philosophical.

This tutorial/guide is being written with the intention of licensing the
material under the http://creativecommons.org/licenses/by-nc-sa/4.0/[Creative
Commons Attribution-NonCommercial-ShareAlike] license.

It is recommended you get familiar with Scala via the first part via the
example `.scala` files provided and loading them into the Scala REPL and
exploring on your own. Inside the example Scala source files I have some
comments to help guide you through it but if you feel it is beating a dead
horse then you should increase the pace.

In the second part, I will link back to the sections in the first part (TODO)
that are relevant to the examples at hand in that subsection. So if you prefer
to get to the meat, then you can just skip to the second part 'Parts to Avoid
(And Their Alternatives)' and then get familiar with the relevant language
features *inline* with the design and philosophy discussion. You should
choose the path that suits your learning style best.

== Important Bits

=== Scala REPL

The first thing you must learn about Scala is that it has a REPL. This allows
you to play around with code interactively. Not only will this help you learn
Scala the language, but as you discover new libraries and APIs it will allow
you to understand how to use them better and more quickly with faster feedback.

Assuming you have Scala installed and in your `PATH`, you should be able to
type `scala` into your shell. When you do, you should see something like this:

[source]
----
$ scala
Welcome to Scala version 2.11.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_25).
Type in expressions to have them evaluated.
Type :help for more information.

scala>
----

=== Functions

Now let's just get started defining some functions in Scala:

[source,scala]
----
include::functions.scala[]
----

Load link:functions.scala[] into your Scala REPL and play with it. To do this start
a Scala REPL in your shell from this directory and then at the prompt type:

[source,scala]
----
scala> :load functions.scala
Loading functions.scala...
defined object sgfunctions

scala> import sgfunctions._
import sgfunctions._

scala> :t f1
Int => Int
----

Now explore on your own. If you need pointers type `:help` at the `scala>`
prompt and then experiment. It can only tell you no. It won't hurl abuse
at you. Wait, till you meet the Scala compiler (`scalac`) and try doing
typelevel stuff for that. ;)

[NOTE]
====
.A few notes on terminology for those new to functional programming not just Scala:
* Functions can and should just be thought of as another kind of value
* You can pass around functions in Scala as arguments to other functions
* Functions can also evaluate to a function value as it's result
* A function that accepts a function as argument or returns a function
  as a result is known as a higher order function (or HOF).
* If a function accepts functions as arguments and also evaluates to a
  function, then we call the special case of a HOF a _combinator_.
====

=== Parametric Polymorphism

If you are familiar with object oriented programming you might be familiar with the
term polymorphism. There are different types, the two we are concerned with
in Scala primarily are paramteric and ad-hoc polymorphism.

When we have a function that is defined the same regardless of a the types used
(as long as they line up with the type signature once the type parameters are
filled in) this is called parametric polymorphism. For example, look at the
following function signatures:

[source,scala]
----
def defaultWith[A](a: A)(ma: Option[A]) = ma match {
  case Some(x)  => x
  case None     => a
}
def mapOver[A, B](f: A => B)(as: List[A]) = as map f
def reduce[A](f: (A, A) => A)(as: List[A]) = sys.error("TODO")
----

You will notice above that we require zero knowledge of what the parameterized
type we are acting on is.

We declare all type parameter names in square brackets before parameter
groups are declared. All `A`s and `B`s in the same function declaration must
line up and be the same when applied.

For example,

[source,scala]
----
val timeoutOpt: Option[Duration] = ...
val timeout: Duration = defaultWith(30 seconds)(timeoutOpt)
----

We will get to an interesting form of Ad Hoc Polymorphism using implicit
parameters later but for now just know that this other form of polymorphism
requires additional knowledge about the the types which can be retrieved
via various mechanisms. In many mainstream OO languages this can be achieved
via method overriding a known interface.

=== Composition

Let's look at a Scala REPL session I started that loaded the previous
`functions.scala` file in:

[source,scala]
----
scala> :load functions.scala
Loading functions.scala...
defined object sgfunctions

scala> import sgfunctions._
import sgfunctions._

scala> transformText(lowerCase, "YO YO YO DAWG")
res0: String = yo yo yo dawg

scala> transformText(prefix("$ "), "ls -la")
res1: String = $ ls -la

scala> transformText(parens, "I love you")
res2: String = (I love you)
----

Here we are using a higher order function (HOF) called `transformText`
which I defined in the `sgfunctions` object of the examples.

Now this is all well and nice, but what's the point of showing this
code?

Well so far it's not that interesting so let's explore a concept that
comes from mathematics. OMG MATHZ!!!11

Yeah, it's gonna come up again. Pretty soon but don't worry, it's our
friend.

.Composition is a simple way to line up functions when their types
line up.

What would this look like for our example. Say we wanted to `parens`
a peice of text and then prefix it. Well we already wrote the definitions
of each part. I don't want to now have to define a `parensAndPrefix`
function now.

Great news, we don't have to. Instead we just do this:

[source,scala]
----
scala> transformText(parens _ andThen prefix("$ ") _, "ls -la")
res6: String = $ (ls -la)
----

Alternatively we could say this for the same result:

[source,scala]
----
scala> transformText(prefix("$ ") _ compose parens _, "ls -la")
res7: String = $ (ls -la)
----

I find the first reads better for thos that are newer to these ideas.
It's there, use it if it works for you and improves understandability of
your code.

=== Partial Functions

Let us have an uncomfortable chat for a moment. Mathematics is a beautiful
creature. I will be talking about mathematical concepts at various points in
this tutorial. Here's a secret, it is very well guarded too so please don't
spread it, but ... I love mathematics. I knew I had a math(s) problem the
moment I laid eyes on it's elegant and unambiguous definitions, its clarity,
and how well concepts neatly stacked on top of each other producing patterns
at all levels of abstraction.

When we talk about functions in functional programming we are getting this
from mathematics. We have a _domain_ of the function which is the set
of possible inputs for the function.

We can define some functions in Scala like so:

[source,scala]
----
def incr(x: Int): Int = x + 1 // <1>
def decr(x: Int): Int = x - 1 // <2>
def double(x: Int): Int = 2*x // <3>
----
<1> increments input by one
<2> decrements input by one
<3> doubles input

Ignoring the finite bounds of type bounds in computers for a second,
all of these functions are essentially _total functions_. This means that
every possible value in the function's _domain_ can be evaluated for each
function.

Now if we look at the following function definition:

[source,scala]
----
def f(x: Int): Double = (2*x + 3) / x
----

There is now one value that cannot produce a result for this function, `f`.
That value is zero (0) because division by zero is, well, ... not well defined.

This function, `f`, is a partial function. Scala supports the notion of
partial functions in it's standard library. Let's play in the REPL:

[source,scala]
----
scala> val pf = new PartialFunction[Int, Int] {
     |   def apply(x: Int): Int = (2*x + 3) / x
     |   def isDefinedAt(x: Int): Boolean = (x != 0)
     | }
pf: PartialFunction[Int,Int] = <function1>

scala> pf.isDefinedAt(5)
res0: Boolean = true

scala> pf.isDefinedAt(1)
res1: Boolean = true

scala> pf.isDefinedAt(0)
res2: Boolean = false

scala> pf.isDefinedAt(-78)
res3: Boolean = true

scala> pf(5)
res4: Int = 2

scala> pf(1)
res5: Int = 5

scala> pf(-78)
res6: Int = 1
----

So now we can have the caller use the `isDefinedAt` method on the
`PartialFunction` value returned before calling the function with the
input to determine if the function should be called or not.

You typically want to use this when, for specific values of input,
the function may crash or return an unreasonable result for whatever
reason.

[WARNING]
====
A partial function is not the same as a _partially applied function_.

All the latter means is that not all parameter groups have been supplied
to fully evaluate the final value result of the function.
====

=== Traits

Traits in Scala are very similar to Java's interfaces, although more flexible.

In Java 8, Java now has the capability of defining default implementations
for interface methods that can be overrided further down the hierarchy. This
has been possible in Scala, well at least since 2.8 when I started using it in
earnest.

Here's an example:

[source,scala]
----
trait Worker {
  def interval: Int = 30
  def init(c: Config): Unit
  def finish(r: Reason): Unit
  def run: Unit
}
----

You can see here we defined a default implementation for `interval`.

I use `trait`s and `abstract class`es in Scala to declare the names
of my (interface) types. These are the only custom types that should
ever appear in type signatures for functions as a general rule. This
is where other Scala developers will disagree, but this is the point
of having an opinionated guide to Scala. Right? :) Play in your REPL,
build Scala programs, and read around the topic more. Through experience
you will form your own opinion, but remember when you come back to this
general rule that we can still be friends (just not BFFs) if you choose
as different Scala path!

I generally dislike using `traits` to define interfaces the way you
would think about them in Java. We'll get back to that later in the
'Parts To Avoid'.

=== Case Classes & Case Objects

Case classes are a simple way to define value constructors for your _types_
(e.g. `trait` or `abstract class` definitions). For example,

[source,scala]
----
trait User
case class Admin(login: String) extends User
case class Editor(login: String, canEditOthers: Boolean) extends User
case class Author(login: String, canSubmitWork: Boolean) extends User
----

Here we have three subtypes of `User` defined in this scope. We have
arguments we can pass in to each case class (or value constructor).

Now there is also the notion of a `case object`. Let's see when we
might use that instead:

[source,scala]
----
trait Direction
case object North extends Direction
case object South extends Direction
case object East extends Direction
case object West extends Direction
----

So we don't need to pass in any arguments. The value constructors
pretty much define the specific value of the type `Direction`
completely without additional context in this case.

If you load the link:caseobjects.scala[] file a run the `DirectionMain`
object (`import sgcaseobjects._; DirectionMain.main(Array.empty[String])`)
then you can see that case objects (as well as case classes) have some
methods already overridden to remove some extra boilerplate from the app
developer's plate. Namely Java's `equals`, `hashCode`, and `toString`.

Let's see what my Scala REPL (shell) session showed me:

[source,scala]
----
scala> :load caseobjects.scala
Loading caseobjects.scala...
defined object sgcaseobjects

scala> import sgcaseobjects._
import sgcaseobjects._

scala> DirectionMain.main(Array.empty[String])
North.toString: North
South.hashCode: 80075181
Is West East? false
Is East East? true
What is this thing? OtherDirection(55)
----

Play around more and investigated.

One other thing `case` objects and classes offer is hidden boilerplate
to enable pattern matching which we will explore in the next section.

=== Pattern Matching

Scala has a builtin mechanism that allows us to on any sort of data
construction in an ordered, first-match fashion. This is called
pattern matching. What do I mean by this? We've already seen one
example of this above so let's look at more examples:

[source,scala]
----
include::holidays.scala[]
----

See link:holidays.scala[] for source.

There were two examples above of pattern matching. One based on case value
constructors and the other based on type discrimination of the value in an
overly general case.

A more simplistic example based on raw values that resembles switch/case
statements in other languages is also possible like so:

[source,scala]
----
include::dayofweek.scala[]
----

See link:dayofweek.scala[] for source.

Above we convert from an `Int` value to a case object that we can use in our
program logic.


=== Singleton Objects

We have already seen examples of `object`s. These are typically used for
namespacing functions as you cannot create an instance of this construct
like you can with classes.

See below for an example:

[source,scala]
----
object Yolo {
  def wtf[A](xs: List[A]): A = xs.head // <1>
  def sqrt(x: Double): Double = Math.sqrt(x) // <2>
}

// We use the functions contained in Yolo like so:
val d: Double = Yolo.sqrt(7.6)
val h: String = Yolo.wtf(List.empty[String]) // thank me later :)
----
<1> This is dangerous to do...can you think why? If not Google :)
<2> This is also dangerous and we'll see why later in the second part.

We can also use singleton objects to extend from `App` object which
will give us a way to run a program in Scala and provide the implicit
`main` in the body of the object.

For example

[source,scala]
----
object YoloMain extends App {
  val d: Double = Yolo.sqrt(7.6)
  println("sqrt of 7.6 is: " + d)
  val h: String = Yolo.wtf(List.empty[String]) // thank me later :)
  println("what happened here?")
}
----

We can run this with the following `YoloMain.main(Array.empty[String])`.

=== Companion Objects

There is a special thing call companion objects which is basically just
an `object` in Scala that is named after a trait or abstract class
(technically any `class` but let's pretend I didn't say that since we
shouldn't need to define any plain OO-style classes the majority of
the time).

You must define the companion object in the same file as the trait
or abstract class.

[source,scala]
----
abstract class WorkerType(hasBenefits: Boolean)
// define case class or case object value constructors extending WorkerType here
object WorkerType {
  case object FullTimeEmployee extends WorkerType(true)
  case class PartTimeEmployee(weeklyHours: Int) extends WorkerType(false)
  case object Contractor extends WorkerType(false)

  // body of companion object
  // "class-level" methods on WorkerType here
}
----

Companion objects have special methods `apply` and `unapply`, which assist
with improving value construction and extracting values in pattern matching
case clauses respectively.

A companion object with an `unapply` method is also called an extractor
object but that is just in case you come across the term. It's not very
special besides that.

Above we saw some examples of `apply` for the `DayOfWeek` type, which
accepted an `Int` input and returned a case object value that represents
the days of the week. See link:dayofweek.scala.

.Some points to note are:
* The `apply` method in `DayOfWeek` companion object returns a `Option[DayOfWeek]`.
  This is necessary because we cannot represent all `Int` values as a `DayOfWeek`.
  To express that it is good to return an `Option[A]` where `A` is your type.
* We can refer to constants or enum `Int` values in Java types in the case clause
  for primitive values, e.g. `Calendar.SUNDAY`. This helps us scan the code
  and the compiler will report any typos at compile time so we have higher
  assurance that the code we wrote is doing what we actually expect. Do you
  know if the day of week `Int` constants representing the days of the week
  in `Calendar` start from `1` or start from `0`? You don't need to, nor do you
  need to worry about whether this changed between major versions of Java.

Now let's look at an example of an `unapply` extractor method:

[source,scala]
----
import java.util.Calendar

object UpCased {
  def unapply(s: String): Boolean = (s.toUpperCase == s)
}

object DownCased {
  def unapply(s: String): Boolean = (s.toLowerCase == s)
}

object InternetMinor {
  def unapply(i: Int): Boolean = (i < 13)
}

case class User(login: String, fullName: String, age: Int)

// Using these extractors
def reportUserCreationSuccess(u: User) =
  user match {
    case User(_, _, age @ InternetMinor()) =>
      println("You are too young to create an account")
    case u =>
      println("Hooray! You can create an account")
  }

// reportUserCreationSuccess(User("mbbx6spp", "Susan Potter", 27)) // what is a white lie between friends?
// reportUserCreationSuccess(User("elliphant", "Ellinor O", 29))
// reportUserCreationSuccess(User("pandabear", "Panda", 11))
----

=== Sealed

This keyword just means that whatever you seal (e.g. trait, abstract class, etc.)
cannot be extended outside of the file it was defined within.

This makes using the Java conventions of one interface or class per source
file not something that can be done easily if you want to build a closed
type with extensions to the kind of entity you are creating sealed.

[source,scala]
----
// inside operators.scala
sealed trait Operator
case class Addition(lhs: Int, rhs: Int) extends Operator

// inside anotherfile.scala but same package
case class Multiplication(x: Int, y: Int) extends Operator // results in compile error
----

.TODO: brief introduction to the following:
* using objects for packaging
* implicit parameters
* type constructors
* type aliases
* useful types (stdlib)
* useful types (scalaz)


== Parts To Avoid (And Their Alternatives)

Scala is a kitchen sink language. This has pros and cons. In reality you
cannot please everyone and the Scala community has had its fair share of
drama in part due to its _kitchen sink philosophy_.

.It does, however, offer:
* a well typed language (assuming you know how to harness the power of its
  type system)
* a language with standard library that is production ready
* a compiler that generates fairly performant JVM bytecode in many cases
  (at least compared to other non-Java JVM language offerings)
* JVM language tooling that is evolving into maturity (I cannot comment on
  the present state of it's CLR tooling)
* it also runs on the JVM as well as the CLR for .NET proponents.

Until a viable alternative is proposed for the JVM (the runtime I typically
need to target at work), the trick for me is to know what parts of the
kitchen sink language to avoid.

The following subsections will discuss the parts of the language I think you
should avoid when first diving in and what alternative constructs to use.

The general claim I make is that imperative and object oriented constructs of
the language should be avoided except when wrapping or calling ill-defined
Java or Scala dependencies from your code.

Let's begin.

=== Don't Scala Like You Java

Be warned if you are a Scala developer that was brought up the Java Way(tm)
and you write Scala mostly like you previously wrote Java code, your very
core might be offended by reading the subsections under this 'Parts To Avoid'
section.

It might mean unlearning a considerable amount that you have immense muscle
memory for. This can make a person feel quesy or unsettled. I just want you
to know, it's ok. There is no judging here, just my strong opinions about
what I have seen work and not work in Scala projects so far.

This is the general complaint of mine that if you want to get more out of
Scala you shouldn't write Scala in an imperative object oriented way. Why
not just write your code in Java? The savings of writing slightly less
boilerplate code in Scala for the equivalent Java code is offset by the
Scala overheads such as worse IDE support, more tooling headaches, Scala
gotchas in the standard library that you might not be aware of already, and
more.

Specifically you shouldn't need to write an AbstractFactoryFactory at any
time. :)

.More seriously you should avoid these constructs in particular:
* Stack unwinding exceptions
* Imperative loops
* OO classes

Ok, let's go explore the alternatives to these imperative and object oriented
constructs.

=== Avoid Stack Unwinding Exceptions

No matter your programming background it would be hard to avoid having seen
a try/catch/finally or its equivalent in most imperative languages (e.g.
Java, Ruby, Python, etc.). Scala also allows you to do this too.

[source,scala]
----------------------------------------------------------------

  val conn = ...
  try {
    conn.execute(....)
  } catch {
    case se: SQLException => se.printStackTrace; throw se
    case e => throw e // rethrow other exceptions w/o stderr logging
  } finally {
    conn.close
  }
----------------------------------------------------------------

In Scala there are different ways of handling this. First let's look at a
very simple function, `sqrt`. It's purpose is to return the square root
of the given double value. The problem is it can accept any `Double`,
including negative ones.

[source,scala]
----------------------------------------------------------------
def sqrt(d: Double): Double =
  if (d < 0) { throw new ArgumentException("We can't square root a negative value") }
  else { Math.sqrt(d) }
----------------------------------------------------------------

This approach of throwing an `ArgumentException` is a problematic way to
solve the issue, but is one that is commonly reached for. You are forcing the
caller to have to either wrap their call to your function inside a try/catch
or a try/finally block or "leak" an exception to its caller. This seems
brittle at best.

Other times I have seen something like this to "solve" the issue, but this
gives an incorrect result when the input is negative, which I am not fond of:

[source,scala]
----------------------------------------------------------------
def sqrt(d: Double): Double =
  if (d <= 0) { 0 }
  else        { Math.sqrt(d) }
----------------------------------------------------------------

A more correct approach might be to change the type signature from `Double =>
Double` to `Double => Complex` where you define a custom type `Complex` and
implement appropriately. This is a correct solution, but not necessarily
always what the consumer of your APIs want. You might provide this variant of
the square root function along with one that is `PartialFunction[Double, Double]`
as this offers the chance for the caller to _do the right thing_ and models
this situation appropriately. It is a partial function when you go from a
`Double` and expect a `Double` as a result.

Let's see what this might look like:

[source,scala]
----
def sqrtPF = new PartialFunction[Double, Double] {
  def apply(d: Double): Double = Math.sqrt(d)
  def isDefinedAt(d: Double): Boolean = (d >= 0)
}

// The caller of your code then _should_ do this:
if (sqrtPF.isDefinedAt(doubleFromExternalInput)) {
  val result = sqrt(doubleFromExternalInput)
  // Do something with result here...
} else {
  // Do whatever should be done for the case that input is
  // not well defined for this partial function.
}
----

Another alternative is to return an `Option[Double]`. This might look
something like the next snippet of code:

[source,scala]
----------------------------------------------------------------
def sqrt(d: Double): Option[Double] =
  if (d < 0) { None }
  else       { Some(Math.sqrt(d)) }
----------------------------------------------------------------

This does express in some way that a `Double` value isn't always the most
appropriate value for a result. Instead no value for square root can be
calculated for certain inputs (i.e. for inputs that are negative).

This is exactly what the type `Option[A]` expresses for any type `A`.
Sometimes the value is an actual value in `A`, others it is just `None`.

This forces the caller of the function to at least willfully ignore the case
where the value returned is `None` or at a minimum suggest it handles it
via the type.

This also does a good job of representing the domain area. Before we continue
I think we have exhausted good alternatives for this specific case of the
`sqrt` function so let's move on to a slightly different use case to look
at other alternatives for a different usage.

*TODO: change the rest of this subsection to swap out `sqrt` function use
case with `parseUserIdFromQueryString`.*

You might instead though want to inform the caller exactly why there is
no value. This is where you might first reach for `Either[E, A]`. Essentially
it can hold either a value of `E` (the _error_ type) or a value of `A`.

Let's see what this might look like:

[source,scala]
----------------------------------------------------------------
def parseUserIdFromQueryString(s: String): Either[String, Int] =
  sys.error("todo")

  // calling code would do something like...
  parseUserIdFromQueryString(userInput) match {
    case Left(reason) => println("Error: " + reason)
    case Right(x)     => println("Result: " + x.toString)
  }

  // However because Either does not have map/flatmap defined...we can't do:
  // Assume: findByUserId type is `Int => User` and `User` is a custom type
  for {
    i <- parseUserIdFromQueryString(userInput) // only pull out if "success" or "right"
    u <- findUserById(i) // not sure why you would do this; it's just for show
  } yield u
----------------------------------------------------------------

The above code now gives us a reason (as a String) for why we don't get
back a _success_ (or `Right`) value. At least that is something.

Now in the example above the `Option[Double]` probably works more often
than not.

Now let's say we instead have a more interesting use case. We have a need
to be able to sequence "successful" value pulls for a structure semantically
_like_ `Either`. Well, there is a library called Scalaz (pronounced "Scala
Zed") that has a type called `\/[E, A]` (pronounced "Disjunction"). Here is
how we would construct and use such a type:

[source,scala]
----------------------------------------------------------------
// do the imports for the Scalaz library
import scalaz._
import Scalaz._

final case class User(id: Int, billingInfo: Option[BillingInfo], ...)
def findUserById(id: Int, conn: DBConnection): Option[User] =
  conn.executeSQL("SELECT * FROM `users` WHERE id = ?", id).headOption map toUser

// inside your logic to return billing info of a user
val result: String \/ User = for {
    u <- findUserById(userInput, dbconn) \/> s"No user found with id ${userInput}"
    b <- u.billingInfo \/> s"User ${userInput} has no billing information"
  } yield b
----------------------------------------------------------------

Here it becomes more important to understand where the error occurred.

The above shows how we can solve in a specific sequence of actions. Sometimes
we want to _run_ validations on data and one isn't dependent on the others,
thus we want an accumulation of errors rather than the first error that
occurs in the sequence of actions we are performing.

Think of a web form submitted by a user. Obviously we should have client
side checking, but the form could be submitted from anywhere on the
internet or via a `POST` HTTP API for automation.

[source,scala]
----------------------------------------------------------------
def validEmailAddress(email: String): ValidationNel[String, EmailAddress] = ...
def validUsername(username: String): ValidationNel[String, Username] = ...
def validAge(dob: String): ValidateNel[String, Age] = ...

val form: Map[String, String] = request.httpParams

val result = validEmailAddress(form["email"]) |@| validUsername(form["username"]) |@| validAge(form["dob"]) {
  case (email, username, age) => sys.error("todo") /* 1 */
}
----------------------------------------------------------------
The part labeled `/* 1 */` in the code is where we put code that only needs
to handle valid email, username, and age objects that were constructed and
validated from the user input. This allows us to focus on the _happy path_
of the coding. If any errors did occur, it would show as a `NonEmptyList`
of string error messages in the result.

Hopefully you can see that avoiding throwing / catching exceptions
in an imperative way and encoding it in more useful types provides us with
much more power and results in simpler, less error prone code. This is
because as callers of better behaved more `total` functions (e.g. not
throwing exceptions that unwind the stack) we can defer _unpacking_
the type and doing what we need to do with the underlying elements
until we have full context to do so. Ever attempted to handle an
exception and realized you didn't have enough context to deal with it?

I know I have, many a time.

=== Avoid Imperative Loops

TODO: show functional List and collection functions and how they are
more powerful than imperative loop constructs and less error prone.

=== Avoid Object Oriented Classes

Yep. You read that heading right. Forget OO classes. OMGFMLWTF!? I am not
saying you forget OO classes in an only-OO language (e.g. Java, Python,
Ruby, etc.). I am saying forget OO classes in Scala (unless required for
a workaround or for the purposes of integrating/wrapping ill-defined Java or
Scala dependencies written in an OO style with exception handling instead of
better types). See I have a caveat there. And that is important if you want
to deliver systems that use other libraries even the Java or Scala standard
library APIs. Perhaps especially them. :)

Ok, I've lost some of you already and that's ok. I love you anyway (I have a
big heart). Bear with me while I make a case for this seemingly insane idea.

.What do we normally use classes for in the OO sense?

Pause a minute. Think about this on your own before proceeding. Here's a
flower:


                 , .-.-,_,
                 )`-.>'` (
                /     `\  |
                |       | |
                 \     / /
                 `=(\ /.=`
                  `-;`.-'
                    `)|     ,
                     ||  .-'|
                   ,_||  \_,/
             ,      \|| .'
             |\|\  , ||/
            ,_\` |/| |Y_,
             '-.'-._\||/
                >_.-`Y|
                ` .-"||"-.
                  \'----'/
                   |:.  |
                   |::. |
                  /::::  \
                .:::'     '.
               /:::         \
              ;:::'          ;
              |:::           |
              |:::           |
              |:::           |
              ;:::           ;
              \:::.          /
           jgs ':::..      .'
                `""-----""`


I mean it. Just think for a moment and meditate.



                                                  ____
       ___                                      .-~. /_"-._
      `-._~-.                                  / /_ "~o\  :Y
          \  \                                / : \~x.  ` ')
           ]  Y                              /  |  Y< ~-.__j
          /   !                        _.--~T : l  l<  /.-~
         /   /                 ____.--~ .   ` l /~\ \<|Y
        /   /             .-~~"        /| .    ',-~\ \L|
       /   /             /     .^   \ Y~Y \.^>/l_   "--'
      /   Y           .-"(  .  l__  j_j l_/ /~_.-~    .
     Y    l          /    \  )    ~~~." / `/"~ / \.__/l_
     |     \     _.-"      ~-{__     l  :  l._Z~-.___.--~
     |      ~---~           /   ~~"---\_  ' __[>
     l  .                _.^   ___     _>-y~
      \  \     .      .-~   .-~   ~>--"  /
       \  ~---"            /     ./  _.-'
        "-.,_____.,_  _.--~\     _.-~
                    ~~     (   _}       -Row
                           `. ~(
                             )  \
                            /,`--'~\--'~\
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             ->T-Rex<-


Hopefully you agree that for the most part (without getting too formal or
pedantic with wording or definitions) we use classes to define types,
their basic structure, implement its public interface in methods that are
grouped/namespaced under it. At least primarily.

So to state it another way, we are bundling type structure and grouping
behaviors of that type together.

If you disagree here then submit a pull request so we can have a respectful
though hopefully meaningful and lively (passionate) debate about this.

_Ok, now what if I told you that you really just want types and functions?_

And coupling them together isn't all that meaningful if you have sane,
consistent and intuitive namespacing. In fact using classes, may even be
detrimental in some cases. There might also be better ways to define types,
interfaces, and the mappings between them. :)

Ok, I lost the next round of you on this suggestion. Again I really
do still love you all. It's cool. We can still be friends, though friends
don't let friends use OO classes and interfaces in languages with better
types available to "model" software without fair warning. :)

I will illustrate with an example, which may or may not sway you if you
aren't already curious or open to change. Remember it is just an example
to illustrate the point. This doesn't prove anything. It is just an
illustration that you don't need to use OO classes to model this case
well (arguably better than using OO patterns).

==== Illustration: Closed Types

Let's say you are building a CI/CD pipeline in Scala. Why not? Ok, now
we want to model the following "world" in software:

* We have four different environments: local, integ, staging, production.
* Developers make their changes for new features or bugfixes in their
  local environment first, write tests (hopefully), add those tests
  to the test suite, and submit a code review for the rest of the team
  and CI system to _evaluate_.
* Other team members will review the code change for code style and
  high level semantics and structure. When they like what they see in
  the review they will "+2 review" it. If they have minor comments that
  need addressing but do not need to re-review after the changes are made
  they can "+1 review" the change. When those minor comments are addressed by
  the author they can give themselves a "+2 review" assuming another reviewer
  has already "+1 review"-ed a previous patchset of the review.
* A `precommit` hook will be triggered upon initial submission of the review
  (and any subsequent changes to the review) which will run automated
  check style, static analysis, and unit test suite runs and report
  success or failure of these checks back to the review system as a "+1
  verify" from the CI system user.
* Once both a human reviewer +2s the change and the CI server running
  the `precommit` hook +1s the change, the author can submit the change
  to the non-prod line persistent branch (let's say `develop`). Although
  this isn't my preferred way of operating, most people are used to the
  git-flow inspired workflow which this is emulating.
* At this point a `commit` hook is triggered in the CI server and run.
* This `commit` hook could tag the change for automatic deployment to
  the integ environment, once integ is running with the new code, we run
  an integration and system level test suite against the running environment,
  to validate the runtime characteristics of the code as defined in the
  (hopefully) newly added tests.
* Once the integ deployment, and tests run successfully for this change,
  this then gets promotes to the staging environment where it can sit there
  with more data and hits using the new feature (hopefully). Manual
  verification may be required at this stage. This is where the develop CI/CD
  line ends for the moment.
* When you have a set of changes on the staging environment that are deemed
  stable enough to deploy to production after automated, long running, and/or
  manual verification checks and tests suites run against it, we "promote" to
  production by creating a new review from the develop branch to the master
  branch.
* Upon submitting the change to master, an automatic deployment to production
  is triggered (hopefully you have zero-downtime deployments scripted already).

In our case the review system is Gerrit, but it could be Github, Bitbucket,
Stash/Crucible, or whatever. We just assume there will be some API and
webhooks available to integrate with the code review system and the CI
server which actually RUNS the `precommit` hook.

What we want to build is a CI/CD "conductor" system that controls the logic
and throttles and controls the various CI and deployment jobs that are
triggered in the interaction between the review system and the CI server.

Our CI/CD "conductor" service will receive requests from the review system
in webhook callbacks (via HTTP) and then determine the appropriate course
of action based on some state for the service/project and the state of
the deployments for each environment for it.

Let's take a first cut at just the types without the notion of OO classes.
There are many ways we can model this in OO so I will not attempt to here:

[source,scala]
----------------------------------------------------------------

/* Here we are creating a "closed" type, where the type used in interfaces
 * is the trait and the "constructors" to create the value of such a type
 * is limited to just the case objects/classes that extend from this sealed
 * trait. This means that the only possible ways we can construct a value
 * of the type `Environment` is using one of the case objects listed below
 * that extend from it. This has practical implementations in terms of what
 * the compiler can tell her about our logic later on.
 */
sealed trait Environment
final case object Local extends Environment
final case object Dev extends Environment
final case object Integ extends Environment
final case object Staging extends Environment
final case object Production extends Environment

/* Note: sometimes the type of type created above is named a Sum type, other
 * times it's called a (Disjoint) Union type.
 * The reason for this is the sum of all the case objects/classes of the
 * type (`Environment` in this case) comprise the full set of possible
 * values for the type. I will use the terminology of Sum and Product
 * types throughout this documentation.
 */

/* Here are the value constructors */
final case object Abandon extends ReviewScore
final case object Refactor extends ReviewScore
final case object SwitchReviewer extends ReviewScore
final case object MinorComments extends ReviewScore
final case object Accepted extends ReviewScore
/* Here is the "type" */
sealed trait ReviewScore
// For each "type" we can define a companion object with
// helper/convenience functions. Here we define mapping
// between the int values used in our review system to
// indicate the different score intents and the value
// constructors of the +ReviewScore+ type.
object ReviewScore {
  def intScore(score: ReviewScore): Int = score match {
    case Abandon        => -2
    case Refactor       => -1
    case SwitchReviewer => 0
    case MinorComments  => 1
    case Accepted       => 2
  }

  def fromInt(intScore: Int): Option[ReviewScore] = intScore match {
    case -2 => Some(Abandon)
    case -1 => Some(Refactor)
    case 0  => Some(SwitchReviewer)
    case 1  => Some(MinorComments)
    case 2  => Some(Accepted)
    case _  => None
  }
}

sealed trait ChangeEvent
final case object ReviewPublished extends ChangeEvent
final case object ReviewUpdated extends ChangeEvent
final case object ReviewSubmitted extends ChangeEvent
final case class ReviewReviewed(score: ReviewScore) extends ChangeEvent
final case class ReviewVerified(url: URL) extends ChangeEvent
final case class ChangeDeployed(env: Environment) extends ChangeEvent
final case class DeployVerified(env: Environment) extends ChangeEvent
final case class ChangePromoted(env: Environment) extends ChangeEvent

object Functions {
  // TODO
}


----------------------------------------------------------------

Now I am going to refactor this based on the practices I advocate. Firstly
notice that there is a lot of pollution in the namespace/package we define
our types and value constructors inside. Above we didn't specify the
package that we would put our definitions in, so we should add a package
declaration so we don't pollute the global namespace with all these names.

This is simple at the top of the file we would put:

[source,scala]
----------------------------------------------------------------
package conductor
----------------------------------------------------------------

Ok, on to the next transformation of the simplest way of defining algebraic
data types (including the sum types above). We are still polluting our
`conductor` package namespace quite a bit and we only just got started with
our types for such a simple application.

Also note if we were to define a `initialChangeEvent` function inside of
the Functions object and we defined it as below, you will notice that
type inference in Scala does not do us justice.

[source,scala]
----------------------------------------------------------------
scala> def initialChangeEvent = ReviewPublished
initialChangeEvent: ReviewPublished.type

scala> :t initialChangeEvent
ReviewPublished.type
----------------------------------------------------------------

Instead of setting the return type of `initialChangeEvent` to the trait,
`ChangeEvent`, it is setting it to the object type of the value constructor.

This can cause us problems as we define more and more functions that might
use Scala's type inference when we use `initialChangeEvent`.

So here is my recommendation to solve both these issues:

[source,scala]
----------------------------------------------------------------

sealed trait ChangeEvent
object ChangeEvent {
  final case object ReviewPublished extends ChangeEvent
  final case object ReviewUpdated extends ChangeEvent
  final case object ReviewSubmitted extends ChangeEvent
  final case class ReviewReviewed(score: ReviewScore) extends ChangeEvent
  final case class ReviewVerified(url: URL) extends ChangeEvent
  final case class DeployVerified(env: Environment) extends ChangeEvent
  final case class ChangeDeployed(env: Environment) extends ChangeEvent
  final case class DeployVerified(env: Environment) extends ChangeEvent
  final case class ChangePromoted(env: Environment) extends ChangeEvent

  def reviewPublished: ChangeEvent = ReviewPublished
  def reviewUpdated: ChangeEvent = ReviewUpdated
  def reviewSubmitted: ChangeEvent = ReviewSubmitted
  def reviewReviewed(score: ReviewScore): ChangeEvent = ReviewReviewed(score)
  def reviewVerifed(url: URL): ChangeEvent = ReviewVerified(url)
  def deployVerified(env: Environment): ChangeEvent = DeployVerified(env)
  def changeDeployed(env: Environment): ChangeEvent = ChangeDeployed(env)
  def deployVerified(env: Environment): ChangeEvent = DeployVerified(env)
  def changePromoted(env: Environment): ChangeEvent = ChangePromoted(env)
}

object Functions {
  def initialChangeEvent = ChangeEvent.reviewPublished
}

----------------------------------------------------------------

Here you will notice there is a lot more boilerplate, but we can control
the value constructor's type inference now and we might possibly (although
we haven't yet) be able to "hide" the value constructors so the only way
for consumers of the `ChangeEvent` type to create values is via the companion
object's helper methods that have the correct return type.

If we check the type of the `initialChangeEvent` function now, we get back
what we want, which is `ChangeEvent`.

It also means we have more semantic context when we are creating values of
this sum type. We use `ChangeEvent.reviewUpdated` instead of just
`ReviewUpdated` which might not read well for reviewers or those newer to
the codebase. So we solved the namespace pollution problem too.

I do strongly suggest you use this style for sum types consistently. So
as an exercise convert the other sum type and value constructor definitions
above to the style implemented for `ChangeEvent` in the code snippet directly
above.

Note: I usually define sum types with a couple of minor alterations to the
above in my own production code in Scala, but this will get you far without
needing to understand `@inline` and why you might use them for the constructor
helper methods in the type's companion object.

Now writing the finite state machine for the CI/CD conductor application
shouldn't be too hard...

[source,scala]
----------------------------------------------------------------

// I assume you refactored the sum types above to the form suggested for
// `ChangeEvent` already.

// Adding some types here...

// A product type that represents a ticket for either a bugfix or a new
// feature. See below for understanding what a product type is (basically
// it just takes multiple values in it's value constructor and it's
// cardinality can be defined by the product of the cardinality of it's
// constituents. i.e. all possible values of this product type are all
// possible values for it's first constructor argument multiplied by the
// next constructor argument's possible value space multiplied ... and so
// on.
//
// Case classes are not OO classes. They provide a way to naturally do
// pattern matching without extra boilerplate code inside a companion object
// plus they are (by default) immutable. You typically will not be defining
// methods directly on case classes or objects unless they are query
// convenience methods.
final case class Ticket(ticketType: TicketType, id: String)

sealed trait TicketType
object TicketType {
  final case object Bugfix extends TicketType
  final case object Feature extends TicketType
  final case object Automation extends TicketType

  @inline def bugfix: TicketType      = Bugfix
  @inline def feature: TicketType     = Feature
  @inline def automation: TicketType  = Automation
}

object Functions {
  def initialChangeEvent = ChangeEvent.reviewPublished
  def initialChangeStatus = ChangeStatus.inReview

  final case class State(
      ticket: Ticket
    , review: Review
    , status: ChangeStatus,
    , isVerified: Boolean
    , isReviewed: Boolean)

  type ProcessResult = (IO[Unit], State)
  def processChangeEvent(evt: ChangeEvent, s: State): ProcessResult = evt match {
    case ChangeEvent.ReviewPublished  => (triggerCIPrecommitHook(s.ticket, s.review), s)
    case ChangeEvent.ReviewUpdated    => (triggerCIPrecommitHook(s.ticket, s.review), s)
    case ChangeEvent.ReviewSubmitted  => (triggerCICommitHook(s.ticket, s.review), s.copy(status=ChangeStatus.submitted))
    case ChangeEvent.ReviewReviewed(score) =>
      score match {
        case Abandon        => (abandonReview(s.ticket, s.review), s)
        // wait for another change event before proceeding
        case Refactor       => (IO {}, s.copy(isReviewed=false)
        case SwitchReviewer => (suggestNewReviewer(s.ticket, s.review), s.copy(isReviewed=false)
        // wait for another change event before proceeding
        case MinorComments  => (IO {}, s.copy(isReviewed=true))
        case Accepted       => (autoSubmit(s.ticket, s.review), s.copy(isReviewed=true)
      }
  }
  // EXERCISE1: Does this compile? Any warnings (make sure to turn warnings on)?
  // EXERCISE2: Fix the errors or warnings yourself. Yes, I am a mathematician
  //            why do you ask? ;)

  def triggerCIPrecommitHook(t: Ticket, r: Review): IO[Unit]  = sys.error("todo")
  def triggerCICommitHook(t: Ticket, r: Review): IO[Unit]     = sys.error("todo")
  def abandonReview(t: Ticket, r: Review): IO[Unit]           = sys.error("todo")
  def suggestNewReviewer(t: Ticket, r: Review): IO[Unit]      = sys.error("todo")
  def autoSubmit(t: Ticket, r: Review): IO[Unit]              = sys.error("todo")
}
----------------------------------------------------------------

The benefit here of defining our types using sum and product types in place
of OO classes are:
* Sum types allow us to get feedback from the compiler as to whether
  functions that pattern match on the value constructors cover all cases
  of the type or not. This is very valuable and can find annoying bugs much
  earlier if you turn on compiler warnings and actually read them. :)
* By default sum and product types offer immutability, forcing the caller
  to copy the values with defined changes to return or pass into other
  functions. This makes understanding code flow and logic much easier
  and eliminates a whole class of bugs that implicit mutation in typical
  OO class style yields.
* We simplify the code by separating data structure from logic.
* The observant reader might notice `ProcessResult` is a tuple of `(IO[Unit],
  State)`. We return the IO actions that need to be performed plus the new
  state. This is expressing effects in the type signature (although there are
  better ways to do this) as opposed to implicit side effects. This is
  important for an idea in functional programming to uphold _referential
  transparency_. I till talk about this a little more later.

_Note: OO philosophy has changed recently to prefer immutability and "value
objects" over traditional mutable objects, but that's heavily influenced by
algebraic data types and it's really how I would define OO-style classes._

While it is great that OO is finally recognizing how implicit mutability
impacts code complexity and increasing maintenance costs and now advocates
for more FP ideas, it still condones complecting the type structures,
interfaces, and behaviors together. This troubles me. :)

Hopefully the next illustration demonstrates how we can extend types using
a very FP construct, typeclasses. In Clojure, you might know this as
`protocols`. In Haskell and Scala they are called `typeclasses` although in
Scala we use a couple of language features in conjunction to emulate them
since the language itself doesn't support typeclasses directly. (Note:
technically the Clojure language doesn't support typeclasses as first
class idea since defining a protocol is just a macro.)

==== Illustration: Extending Types

So let's say you have this SaaS application already shipped and it's a
cool app but your customers (aka tenants) are asking for a better
administrative and billing control panel for both internal and external use.
You have the old admin console which barely works, it's written in a language
that was hip 5 years ago and your codebase is a total mess for it.

Nobody wants to touch it because of the quality and instability of the
environment, dependencies, and brittleness of the admin app. It is
demotivating your engineers. Even the ones that aren't totally burned out
from 3 years working crazy hours in your startup requiring 80 hour weeks
minimum most weeks but also the new hires.

Management finally agrees to rewrite just that admin console piece in an
iterative fashion, one endpoint at a time which will be validated and
delivered to "beta" tenants and internal users as they are available.

After much research you choose Scala as the language because ... well who
cares why honestly. You chose it for the purposes of this illustration. :)

Let's pretend we already ported over the Identity, AuthN and AuthZ parts of
the code to the JVM and this is available as a library for your Scala service.

You have to keep the same server-side API contract with the legacy admin
console so that you can avoid totally rewriting the front end just yet. Ok,
this is a big assumption, but I am not here to manage your software rewrite
project risks right now. We are learning the right way to model your app
in Scala WITHOUT OO CLASSES.

Let's say your legacy admin console has these notions (and it's reflected in
the HTTP API your UI is querying and updating adequately):

* Customer (aka tenant) information such as admin, billing, support
  contacts, customer type (e.g. individual or organization), and the customer
  billing plans (with effective and expiration dates for history and billing
  calculation purposes).

Those are the top level notions but we can quickly see that the following
fall out from the observations of our current API:

* Billing plan
* Contact
* Billing status

I could go on, but I don't think it adds too much value to do so for the
purpose of this illustration.

In an OO style Scala implementation we might write something that looks like
this (structurally):

[source,scala]
----------------------------------------------------------------

trait Customer { /* define interface for customer here */ }
// Note these are far from one liner definitions typically, but LOCs are
// not under discussion here as it detracts from the bigger points.
class IndividualCustomer extends Customer {
  /** define implementations of required Customer methods found in trait
    * plus any other private methods that might be needed internally and
    * all possible OO "constructors" for creating values of this subclass.
    */

}
class BusinessCustomer extends Customer { /* see above comment */ }
class GovernmentCustomer extends Customer { /* see above comment */ }

// ... and it goes on ...

----------------------------------------------------------------

Instead we can just separate the behaviors from the type's interface,
and its structure.

Let's have a look at the first cut of how we could do that:

[source,scala]
----------------------------------------------------------------

/* Here we define the types in a sum type, which you can think of like
 * a better enum.
 */
sealed trait ContactType
final case object AdminContact extends ContactType
final case object BillingContact extends ContactType
final case object SupportContact extends ContactType

/*
 * Here we have one way to define the structure of a contact, so we
 * create what is called a product type, where it's value constructor
 * accepts two or more values of other types. The value represented is
 * a product (in this case) of a:
 * ContactType x String x String x String x List[PhoneNumber] x List[EmailAddress]
 * This "product" of it's constituents defines all possible values of this
 * type.
 */
final case class Contact(
    contactType: ContactType
  , firstName: String
  , lastName: String
  , title: String
  , phoneNumbers: List[PhoneNumber]
  , emailAddresses: List[EmailAddress])

/* Again another natural sum type arises in the domain with CustomerType
 */
sealed trait CustomerType
final case object IndividualCustomer extends Customer
final case object BusinessCustomer extends Customer
final case object GovernmentCustomer extends Customer

/*
 * Now things get a little interesting. We have a sum-product type defined here.
 * Some or all of our sum constructors accept two or more inputs to create
 * it's value.
 *
 * This is still an algebraic data type (sum, product, recursive, hybrid), it
 * just happens to be a hybrid of sum and product types.
 */
sealed trait BillingPlan
final case class SMBPlan(userCount: Int, featureAMax: Int, ...) extends BillingPlan
final case class ProPlan(...) extends BillingPlan
final case class GovtPlan(...) extends BillingPlan

final case class BillingPlanEvent(
    plan: BillingPlan
  , effectiveDate: Date
  , expirationDate: Date)

type BillingPlanHistory = List[BillingPlanEvent]

final case class Customer(
    id: UUID
  , name: String
  , customerType: CustomerType
  , contacts: List[Contact]
  , plan: BillingPlanHistory) {

  def billingStatus: BillingStatus = sys.error("todo")
}

// ...
----------------------------------------------------------------

What we have here is a clean structural model of our problem domain. We
aren't worrying about the specific behaviors we need to support for each
type yet. We don't have to. We can first focus on defining the structure
in a first pass. Then deciphering the specific behaviors we want to support
for each type or combination of them in our specific application.

So now let's tackle one of the behaviors that we must support for the first
endpoint:
* We need to be able to list customers in a natural sortable fashion. We
  should do this on the server side, not the client side. In our case this is
  by name and then id as secondary field to sort on. This is because we might
  have two customers with the same name. It might be two different departsments
  within the same larger company or unrelated companies with the same name
  in different countries.

How can we do this without touching the type definitions above? In Java, this
might be a world of hurt because either we would have to touch the type
definitions (e.g. implement `Comparable<T>` or whatever), create a
delegate class to do this, write a utility helper method which is supremely
non-OO in style anyway, or a combination of the above.

I prefer to only touch my type definitions when I have uncovered new
understanding about my problem domain that needs capturing in the structure
of my types. Not modifying type definitions just for behaviors. This is why
the FP way of thinking fits my mind quite well, and, I think in time, you will
see the benefits of this too. It means you will not need to override subclass
definitions of the `Comparable<T>` interface when you add it to the base class
definition, as one example.

Here is where we introduce typeclasses. This is inherently NOT OO classes.
Despite the name of this concept it has nothing to do with object orientation.

We have previously seen that we have gotten so far with closed types (algebraic
data types of various kinds, e.g. sum, product, hybrid, etc.) but we also need
to enable uniform, and consistent behaviors acting on those types in an "open"
or extensible fashion.

In Java we would define an interface (or in this case reuse the existing
standard interface in the standard library, `Comparable<T>`) and then modify
the `Customer` class definition to implement it. If we modeled `Customer` in
Java as an interface or an abstract class with subclasses for the different
types of customers with different structural representation that the base
class didn't have access to, then we might need to implement
`int compareTo(T t)` in each of the leaf classes. This may not be a big deal
when you only have three subclasses, but it can become unweildy pretty fast.

And frankly it is an unnecessary way of writing code in Scala. In Scala we have
this notion of _implicits_ which are extremely powerful. With all things that
harness power you must be very careful. It can be misused. And frequently is,
however, the usage I will demonstrate, is a good way to make use of this
language primitive. Please read the official documentation on
http://docs.scala-lang.org/tutorials/tour/implicit-parameters.html[Implicit Parameters]
for more information on the language mechanism if you are not familiar first.

Now that you are armed with implicit parameter knowledge, let's look at how we
can use this power wisely to solve the following problem previously outlined:
* Without modifying the type definitions how can we support naturally sortable
  `Customer` values in, say, a list or collection structure.

It's important we don't need to touch the type definitions for changes
to behavior like this. It makes our structural model more able to mirror
the real world it is attempting to represent. It also separates implementation
details from the type definitions. Realistically they should be completely
decoupled. If you ship a base class in a foundation library in version 1.x
and forget to implement `Comparable<T>` adding this behavior in to version 2.x
will break a lot of consumers of your library. Then you have to decide do you
prioritize backward compatibility and workaround it in various ways (which
you can do but it adds more noise to both your library and consumer code of
your library) or do you break existing consumers of you library. Neither
scenario is ideal.

[source,scala]
----------------------------------------------------------------
/* For demonstration purposes we will be building out from scratch the `Ord`
 * typeclass. This is actually not at all needed when building real systems
 * and is discouraged. I will discuss how we would use the Scalaz version
 * later on in this illustration. For now, we need to show how we can define
 * typeclasses and extend existing types in our models without touching
 * the original type's external definition though and serves that purpose.
 */
include::ordering.scala[]
----------------------------------------------------------------

See link:ordering.scala[] for the source if this doesn't render correctly.

